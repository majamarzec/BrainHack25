{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743278306.037831  219097 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Przetwarzanie...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743278306.261928  226017 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743278306.293931  226015 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zakończono. Dane zapisane do: movies_head/AOP_Head_normal1.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "VIDEO_PATH = 'movies_head/AOP_Head_normal1.mp4'       \n",
    "OUTPUT_CSV = 'movies_head/AOP_Head_normal1.csv'    \n",
    "\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Błąd: nie można otworzyć pliku {VIDEO_PATH}\")\n",
    "    exit()\n",
    "\n",
    "frame_id = 0\n",
    "all_landmarks = []\n",
    "\n",
    "print(\"⏳ Przetwarzanie...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    row = {\"frame\": frame_id}\n",
    "    if results.pose_landmarks:\n",
    "        for i, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            row[f\"{i}_x\"] = lm.x\n",
    "            row[f\"{i}_y\"] = lm.y\n",
    "            row[f\"{i}_z\"] = lm.z\n",
    "            row[f\"{i}_cs\"] = lm.visibility \n",
    "    else:\n",
    "        for i in range(33):\n",
    "            row[f\"{i}_x\"] = None\n",
    "            row[f\"{i}_y\"] = None\n",
    "            row[f\"{i}_z\"] = None\n",
    "            row[f\"{i}_cs\"] = None \n",
    "\n",
    "    all_landmarks.append(row)\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "df = pd.DataFrame(all_landmarks)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"✅ Zakończono. Dane zapisane do: {OUTPUT_CSV}\")\n",
    "\n",
    "# === FPS and Duration Estimation ===\n",
    "# total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "# print(\"Total frames:\", total_frames)\n",
    "\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)  # Directly obtain FPS from the video metadata\n",
    "# if fps > 0:\n",
    "#     ms_per_frame = 1000 / fps  # Milliseconds per frame\n",
    "#     print(f\"Frames per second: {fps}\")\n",
    "#     print(f\"Milliseconds per frame: {ms_per_frame}\")\n",
    "# else:\n",
    "#     print(\"⚠️ Unable to determine FPS from metadata.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.16 ('DEEPLABCUT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8dc4e3508658d485c4abdd18f5730808a12297bd96dc9bb95f3e29859aae981"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
